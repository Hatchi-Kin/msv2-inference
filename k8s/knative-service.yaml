apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: openl3-inference
  namespace: default
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/scale-to-zero-grace-period: "3600s"
    spec:
      nodeSelector:
        kubernetes.io/hostname: adama
      containers:
        - image: ghcr.io/YOUR_USERNAME/openl3-inference:latest
          ports:
            - containerPort: 8000
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 60
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 5
          resources:
            limits:
              nvidia.com/gpu: 1
          env:
            - name: MINIO_ENDPOINT
              valueFrom:
                secretKeyRef:
                  name: minio-creds
                  key: endpoint
            - name: MINIO_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-creds
                  key: access_key
            - name: MINIO_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-creds
                  key: secret_key
            - name: MODEL_BUCKET
              value: "megaset-sqlite"
            - name: AUDIO_BUCKET
              value: "megaset"
